{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/zsunberg/ai4all-berkeley-driving/blob/master/1-6%20Reward%20Shaping-Good%20Reward.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DeKPHZSDMc0Y"
   },
   "outputs": [],
   "source": [
    "! git clone https://github.com/zsunberg/ai4all-berkeley-driving\n",
    "! pip install stable-baselines\n",
    "! pip install celluloid\n",
    "! pip install numpy==1.17.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UZMZr4SxM0mq"
   },
   "outputs": [],
   "source": [
    "%cd ai4all-berkeley-driving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_0MOAlLeMbpl"
   },
   "outputs": [],
   "source": [
    "from driving.ui import *\n",
    "env = DrivingEnv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ATrhA0mgMbpw"
   },
   "source": [
    "# 1. Goal\n",
    "\n",
    "Go to the track and stay on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5yaPt2tTMbp2"
   },
   "source": [
    "# 2. Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r60y4GD_Mbp3"
   },
   "outputs": [],
   "source": [
    "def my_reward(x, y, theta, a):\n",
    "    # Put your reward function here\n",
    "    # you might want to use the (signed) distance from the track, d\n",
    "    d, angle = env.distance_angle(x, y, theta)\n",
    "    \n",
    "    rda = -0.3*abs(d) - 0.0005*abs(angle) # This penalizes distance from the road and angle from the road\n",
    "    ra = -0.001*abs(a) # This Penalizes Larger Turns\n",
    "\n",
    "    r = rda + ra\n",
    "\n",
    "    if abs(d) <= 0.1:\n",
    "      r = 1 + ra\n",
    "    \n",
    "    if abs(d) >= 2.0:\n",
    "      r -= 20\n",
    "    return r\n",
    "    \n",
    "    \n",
    "env.reward = my_reward\n",
    "plot_reward(my_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wkHb2UalMbp_"
   },
   "source": [
    "# 3. DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iYX7sYWtMbqB"
   },
   "outputs": [],
   "source": [
    "model = StudentQModel(env, exploring_rate=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K-mXalAHMbqH"
   },
   "outputs": [],
   "source": [
    "model.train(100000, model_name=\"my_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cf6TfE4WMbqN"
   },
   "source": [
    "# 4. Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XiqtzeumMbqP"
   },
   "outputs": [],
   "source": [
    "def my_q_policy(x, y, theta):\n",
    "    # implement a policy that maximizes model.q_value(x, y, theta, a)\n",
    "    # just like you did for the reward function\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cyvpvqu5MbqW"
   },
   "source": [
    "# 5. Goal Accomplished!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GKXUL7rjMbqY"
   },
   "outputs": [],
   "source": [
    "cam = record(env, my_q_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ee6F-iTwMbqg"
   },
   "outputs": [],
   "source": [
    "cam.animate().save(\"my_simulation.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XujWcCFLNZdP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "colab": {
   "include_colab_link": true,
   "name": "1-6 Reward Shaping.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
